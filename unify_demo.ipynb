{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tqdm as notebook_tqdm\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import dsp\n",
        "import dspy\n",
        "from dotdict import dotdict\n",
        "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
        "from dspy.evaluate import Evaluate\n",
        "from dspy.teleprompt import BootstrapFewShot, BootstrapFinetune, BootstrapFewShotWithRandomSearch\n",
        "\n",
        "load_dotenv()\n",
        "unify_api_key = os.getenv(\"UNIFY_KEY\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "# Load the dataset.\n",
        "dataset = HotPotQA(train_seed=1, train_size=200, eval_seed=2023, dev_size=1000, test_size=0)\n",
        "\n",
        "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]\n",
        "\n",
        "len(trainset), len(devset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(devset)\n",
        "print(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
        "\n",
        "class QnA(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "    def forward(self, question):\n",
        "        prediction = self.generate_answer(question=question)\n",
        "        return dspy.Prediction(answer=prediction.answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gemma = dsp.Unify(\n",
        "    endpoint=\"gemma-7b-it@anyscale\",\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")\n",
        "\n",
        "claude = dsp.Unify(\n",
        "    endpoint=\"claude-3-haiku@anthropic\",\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")\n",
        "\n",
        "unify_router = dsp.Unify(\n",
        "    endpoint=\"router@q:1|c:1.92e+00|t:7.45e-05|i:1.00e-06\",\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")\n",
        "\n",
        "turbo = dsp.Unify(\n",
        "    endpoint=\"gpt-3.5-turbo@openai\", \n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        "\n",
        ")\n",
        "\n",
        "dspy.settings.configure(lm=turbo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_context_and_answer(example, pred, trace=None):\n",
        "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
        "    return answer_EM\n",
        "\n",
        "num_threads = 24\n",
        "\n",
        "teleprompter = BootstrapFinetune(metric=validate_context_and_answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compiled_qna = teleprompter.compile(QnA(), trainset=trainset[:50], valset=trainset[50:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_hotpot = Evaluate(devset=devset[:1000], metric=validate_context_and_answer, num_threads=num_threads, display_progress=True, display_table=5)\n",
        "evaluate_hotpot(compiled_qna, metric=validate_context_and_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "claude.inspect_history(n=3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
