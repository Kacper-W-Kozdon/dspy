{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tqdm as notebook_tqdm\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import dsp\n",
        "import dspy\n",
        "from dotdict import dotdict\n",
        "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
        "from dspy.evaluate import Evaluate\n",
        "from dspy.teleprompt import BootstrapFewShot, BootstrapFinetune\n",
        "\n",
        "load_dotenv()\n",
        "unify_api_key = os.getenv(\"UNIFY_KEY\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 50)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "# Load the dataset.\n",
        "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
        "\n",
        "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]\n",
        "\n",
        "len(trainset), len(devset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
        "\n",
        "class QnA(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "    def forward(self, question):\n",
        "        prediction = self.generate_answer(question=question)\n",
        "        return dspy.Prediction(answer=prediction.answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "gemma = dsp.Unify(\n",
        "    endpoint=\"gemma-7b-it@anyscale\",\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")\n",
        "\n",
        "claude = dsp.Unify(\n",
        "    endpoint=\"claude-3-haiku@anthropic\",\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")\n",
        "\n",
        "unify_router = dsp.Unify(\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")\n",
        "\n",
        "\n",
        "dspy.settings.configure(lm=gemma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|\u2588         | 2/20 [00:18<02:47,  9.29s/it]"
          ]
        }
      ],
      "source": [
        "def validate_context_and_answer(example, pred, trace=None):\n",
        "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
        "    return answer_EM\n",
        "\n",
        "num_threads = 24\n",
        "\n",
        "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
        "\n",
        "compiled_rag = teleprompter.compile(QnA(), trainset=trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_hotpot = Evaluate(devset=devset[:1000], metric=validate_context_and_answer, num_threads=num_threads, display_progress=True, display_table=0)\n",
        "evaluate_hotpot(gemma)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
