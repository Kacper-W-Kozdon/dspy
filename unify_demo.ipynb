{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import dsp\n",
        "import dspy\n",
        "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
        "from dspy.evaluate import Evaluate\n",
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "load_dotenv()\n",
        "unify_api_key = os.getenv(\"UNIFY_KEY\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "# Load the dataset.\n",
        "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
        "\n",
        "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]\n",
        "\n",
        "len(trainset), len(devset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
        "\n",
        "class RAG(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = self.retrieve(question).passages\n",
        "        prediction = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context, answer=prediction.answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lm1 = dsp.Unify(\n",
        "    endpoint=\"gemma-7b-it@anyscale\",\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")\n",
        "\n",
        "lm2 = dsp.Unify(\n",
        "    endpoint=\"claude-3-haiku@anthropic\",\n",
        "    max_tokens=150,\n",
        "    api_key=unify_api_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_context_and_answer(example, pred, trace=None):\n",
        "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
        "    return answer_EM\n",
        "\n",
        "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
        "\n",
        "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
